{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install the Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: semantic-kernel==0.9.6b1 in .\\.venv\\lib\\site-packages (0.9.6b1)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.8 in .\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (3.9.4)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in .\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (0.7.1)\n",
      "Requirement already satisfied: grpcio>=1.50.0 in .\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (1.62.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in .\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (3.1.3)\n",
      "Requirement already satisfied: motor<4.0.0,>=3.3.2 in .\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (3.4.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in .\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (1.6.0)\n",
      "Requirement already satisfied: numpy>=1.25 in .\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.0 in .\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (1.17.0)\n",
      "Requirement already satisfied: openapi_core<0.20,>=0.18 in .\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (0.18.2)\n",
      "Requirement already satisfied: prance<24.0.0.0,>=23.6.21.0 in .\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (23.6.21.0)\n",
      "Requirement already satisfied: pybars4<0.10.0,>=0.9.13 in .\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (0.9.13)\n",
      "Requirement already satisfied: pydantic<3,>=2 in .\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (2.7.0)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in .\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (1.0.1)\n",
      "Requirement already satisfied: regex<2024.0.0,>=2023.6.3 in .\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (2023.12.25)\n",
      "Requirement already satisfied: scipy>=1.5.0 in .\\.venv\\lib\\site-packages (from semantic-kernel==0.9.6b1) (1.13.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in .\\.venv\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.6b1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in .\\.venv\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.6b1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in .\\.venv\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.6b1) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in .\\.venv\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.6b1) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in .\\.venv\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.6b1) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in .\\.venv\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic-kernel==0.9.6b1) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in .\\.venv\\lib\\site-packages (from jinja2<4.0.0,>=3.1.3->semantic-kernel==0.9.6b1) (2.1.5)\n",
      "Requirement already satisfied: pymongo<5,>=4.5 in .\\.venv\\lib\\site-packages (from motor<4.0.0,>=3.3.2->semantic-kernel==0.9.6b1) (4.6.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in .\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in .\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (0.27.0)\n",
      "Requirement already satisfied: sniffio in .\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in .\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in .\\.venv\\lib\\site-packages (from openai>=1.0->semantic-kernel==0.9.6b1) (4.11.0)\n",
      "Requirement already satisfied: asgiref<4.0.0,>=3.6.0 in .\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (3.8.1)\n",
      "Requirement already satisfied: isodate in .\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.6.1)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in .\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (4.21.1)\n",
      "Requirement already satisfied: jsonschema-spec<0.3.0,>=0.2.3 in .\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.2.4)\n",
      "Requirement already satisfied: more-itertools in .\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (10.2.0)\n",
      "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in .\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.6.2)\n",
      "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in .\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.7.1)\n",
      "Requirement already satisfied: parse in .\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (1.20.1)\n",
      "Requirement already satisfied: werkzeug in .\\.venv\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (3.0.2)\n",
      "Requirement already satisfied: chardet>=3.0 in .\\.venv\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (5.2.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.10 in .\\.venv\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (0.18.6)\n",
      "Requirement already satisfied: requests>=2.25 in .\\.venv\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (2.31.0)\n",
      "Requirement already satisfied: six~=1.15 in .\\.venv\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in .\\.venv\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (24.0)\n",
      "Requirement already satisfied: PyMeta3>=0.5.1 in .\\.venv\\lib\\site-packages (from pybars4<0.10.0,>=0.9.13->semantic-kernel==0.9.6b1) (0.5.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in .\\.venv\\lib\\site-packages (from pydantic<3,>=2->semantic-kernel==0.9.6b1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in .\\.venv\\lib\\site-packages (from pydantic<3,>=2->semantic-kernel==0.9.6b1) (2.18.1)\n",
      "Requirement already satisfied: idna>=2.8 in .\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0->semantic-kernel==0.9.6b1) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in .\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0->semantic-kernel==0.9.6b1) (1.2.1)\n",
      "Requirement already satisfied: certifi in .\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==0.9.6b1) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in .\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==0.9.6b1) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0->semantic-kernel==0.9.6b1) (0.14.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in .\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in .\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in .\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.18.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in .\\.venv\\lib\\site-packages (from jsonschema-spec<0.3.0,>=0.2.3->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (6.0.1)\n",
      "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in .\\.venv\\lib\\site-packages (from jsonschema-spec<0.3.0,>=0.2.3->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.4.3)\n",
      "Requirement already satisfied: rfc3339-validator in .\\.venv\\lib\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.1.4)\n",
      "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in .\\.venv\\lib\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (0.3.2)\n",
      "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in .\\.venv\\lib\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel==0.9.6b1) (1.10.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in .\\.venv\\lib\\site-packages (from pymongo<5,>=4.5->motor<4.0.0,>=3.3.2->semantic-kernel==0.9.6b1) (2.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\.venv\\lib\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\lib\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (2.2.1)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in .\\.venv\\lib\\site-packages (from ruamel.yaml>=0.17.10->prance<24.0.0.0,>=23.6.21.0->semantic-kernel==0.9.6b1) (0.2.8)\n",
      "Requirement already satisfied: colorama in .\\.venv\\lib\\site-packages (from tqdm>4->openai>=1.0->semantic-kernel==0.9.6b1) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install semantic-kernel==0.9.6b1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create your environment variables .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your environment variables then run the cell to create the *.env* file with your environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .env\n"
     ]
    }
   ],
   "source": [
    "%%writefile .env\n",
    "# Environment variables obtained from Azure OpenAI\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"chat-model\"\n",
    "AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME=\"text-embedding-ada-002\"\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME=\"cl-dtp-ais-dev-ws-openai-east\"\n",
    "AZURE_OPENAI_ENDPOINT=\"https://cl-dtp-ais-dev-ws-openai-east-cdn.openai.azure.com/\"\n",
    "AZURE_OPENAI_API_KEY=\"4251b9cd1fec4835aeb98bf1f0c40809\"\n",
    "# Environment variable obtained from Azure Cosmos DB for MongoDB vCore\n",
    "AZCOSMOS_CONNSTR=\"mongodb+srv://aidevadmin:CanadaLife2024@cl-dtp-ais-dev-ws-cosmosdb-csa.mongocluster.cosmos.azure.com/?tls=true&authMechanism=SCRAM-SHA-256&retrywrites=false&maxIdleTimeMS=120000\"\n",
    "# Environment variables you set to be used by the code\n",
    "AZCOSMOS_DATABASE_NAME=\"ragdatabase\"\n",
    "AZCOSMOS_CONTAINER_NAME=\"ragcontainer\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the environment variables file\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the parameters needed by [Azure Cosmos DB for MongoDB vCore](https://learn.microsoft.com/azure/cosmos-db/mongodb/vcore/vector-search) to create the vector search index are handled by semantic kernel.\n",
    "\n",
    "In this guide, we are using `text-embedding-ada-002` embedding model to generate the embeddings which uses a 1536-dimensional embedding vector.\n",
    "\n",
    "The `num_lists` is an integer that represents of clusters that the inverted file (IVF) index uses to group the vector data.\n",
    "\n",
    "The `similarity` used with IVF index here is the `COS` (cosine distance) but you can also try `L2` (Euclidean distance), and `IP` (inner product). For more information see the [Understand embeddings in Azure OpenAI Service article](https://learn.microsoft.com/azure/ai-services/openai/concepts/understand-embeddings#cosine-similarity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection name will be used multiple times in the code so we store it in a variable\n",
    "collection_name = os.environ.get(\"AZCOSMOS_CONTAINER_NAME\")\n",
    "\n",
    "# Vector search index parameters\n",
    "index_name = \"VectorSearchIndex\"\n",
    "vector_dimensions = 1536  # text-embedding-ada-002 uses a 1536-dimensional embedding vector\n",
    "num_lists = 1\n",
    "similarity = \"COS\"  # cosine distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes in a json file of NoSQL records and checks if your data exists in the database using the id of the record then skips the record if it exists or generates embeddings and uploads the database record along with it's embedding.\n",
    "\n",
    "The `save_information` function does two things: generate embeddings + upload the data to your database.\n",
    "\n",
    "Learn more about the semantic kernel memory store [here](https://learn.microsoft.com/semantic-kernel/memories/) and the embeddings [here](https://learn.microsoft.com/semantic-kernel/memories/embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "from semantic_kernel.memory.memory_store_base import MemoryStoreBase\n",
    "\n",
    "\n",
    "async def upsert_data_to_memory_store(memory: SemanticTextMemory, store: MemoryStoreBase, data_file_path: str) -> None:\n",
    "    \"\"\"\n",
    "    This asynchronous function takes two memory stores and a data file path as arguments.\n",
    "    It is designed to upsert (update or insert) data into the memory stores from the data file.\n",
    "\n",
    "    Args:\n",
    "        memory (callable): A callable object that represents the semantic kernel memory.\n",
    "        store (callable): A callable object that represents the memory store where data will be upserted.\n",
    "        data_file_path (str): The path to the data file that contains the data to be upserted.\n",
    "\n",
    "    Returns:\n",
    "        None. The function performs an operation that modifies the memory stores in-place.\n",
    "    \"\"\"\n",
    "    with open(file=data_file_path, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        n = 0\n",
    "        for item in data:\n",
    "            n += 1\n",
    "            # check if the item already exists in the memory store\n",
    "            # if the id doesn't exist, it throws an exception\n",
    "            try:\n",
    "                already_created = bool(await store.get(collection_name, item[\"id\"], with_embedding=True))\n",
    "            except Exception:\n",
    "                already_created = False\n",
    "            # if the record doesn't exist, we generate embeddings and save it to the database\n",
    "            if not already_created:\n",
    "                await memory.save_information(\n",
    "                    collection=collection_name,\n",
    "                    id=item[\"id\"],\n",
    "                    # the embedding is generated from the text field\n",
    "                    text=item[\"content\"],\n",
    "                    description=item[\"title\"],\n",
    "                )\n",
    "                print(\n",
    "                    \"Generating embeddings and saving new item:\",\n",
    "                    n,\n",
    "                    \"/\",\n",
    "                    len(data),\n",
    "                    end=\"\\r\",\n",
    "                )\n",
    "            else:\n",
    "                print(\"Skipping item already exits:\", n, \"/\", len(data), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Add the Chat and Embedding models to the Semantic Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the semantic kernel, and initialize the semantic kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "\n",
    "# Intialize the kernel\n",
    "kernel = Kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the needed libraries.\n",
    "\n",
    "We need the chat completion for having a conversation and text embeddings for generating embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureTextEmbedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the chat deployment name, initialize the chat completions with the required parameters, and add the created chat service to the semantic kernel instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "KernelFunctionAlreadyExistsError",
     "evalue": "Service with service_id 'chat_completion' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKernelFunctionAlreadyExistsError\u001b[0m          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m endpoint \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAZURE_OPENAI_ENDPOINT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAZURE_OPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_service\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mAzureChatCompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mservice_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchat_completion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeployment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchat_model_deployment_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdded Azure OpenAI Chat Service...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\semantic_kernel\\kernel.py:785\u001b[0m, in \u001b[0;36mKernel.add_service\u001b[1;34m(self, service, overwrite)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservices[service\u001b[38;5;241m.\u001b[39mservice_id] \u001b[38;5;241m=\u001b[39m service\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 785\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m KernelFunctionAlreadyExistsError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mService with service_id \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mservice\u001b[38;5;241m.\u001b[39mservice_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKernelFunctionAlreadyExistsError\u001b[0m: Service with service_id 'chat_completion' already exists"
     ]
    }
   ],
   "source": [
    "# adding azure openai chat service\n",
    "chat_model_deployment_name = os.environ.get(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=\"chat_completion\",\n",
    "        deployment_name=chat_model_deployment_name,\n",
    "        endpoint=endpoint,\n",
    "        api_key=api_key,\n",
    "    )\n",
    ")\n",
    "print(\"Added Azure OpenAI Chat Service...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the embeddings deployment name and initialize the text embedding with the required parameters, and add the created embedding service to the semantic kernel instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added Azure OpenAI Embedding Generation Service...\n"
     ]
    }
   ],
   "source": [
    "# adding azure openai text embedding service\n",
    "embedding_model_deployment_name = os.environ.get(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME\")\n",
    "\n",
    "kernel.add_service(\n",
    "    AzureTextEmbedding(\n",
    "        service_id=\"text_embedding\",\n",
    "        deployment_name=embedding_model_deployment_name,\n",
    "        endpoint=endpoint,\n",
    "        api_key=api_key,\n",
    "    )\n",
    ")\n",
    "print(\"Added Azure OpenAI Embedding Generation Service...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Create or Update Azure Cosmos DB for MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The semantic kernel can handel the database, collection, index creation.\n",
    "\n",
    "Import the Azure CosmosDB memory store and initialize it with the parameters defined before.\n",
    "\n",
    "If the database, collection, and index exist it won't overwrite it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating or updating Azure Cosmos DB Memory Store...\n",
      "Finished updating Azure Cosmos DB Memory Store...\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.memory.azure_cosmosdb import (\n",
    "    AzureCosmosDBMemoryStore,\n",
    ")\n",
    "\n",
    "print(\"Creating or updating Azure Cosmos DB Memory Store...\")\n",
    "# create azure cosmos db for mongo db vcore api store and collection with vector ivf\n",
    "# currently, semantic kernel only supports the ivf vector kind\n",
    "store = await AzureCosmosDBMemoryStore.create(\n",
    "    cosmos_connstr=os.environ.get(\"AZCOSMOS_CONNSTR\"),\n",
    "    cosmos_api=\"mongo-vcore\",\n",
    "    database_name=os.environ.get(\"AZCOSMOS_DATABASE_NAME\"),\n",
    "    collection_name=collection_name,\n",
    "    index_name=index_name,\n",
    "    vector_dimensions=vector_dimensions,\n",
    "    num_lists=num_lists,\n",
    "    similarity=similarity,\n",
    ")\n",
    "print(\"Finished updating Azure Cosmos DB Memory Store...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the created memory store to the semantic kernel instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered Azure Cosmos DB Memory Store...\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "from semantic_kernel.core_plugins.text_memory_plugin import TextMemoryPlugin\n",
    "\n",
    "memory = SemanticTextMemory(storage=store, embeddings_generator=kernel.get_service(\"text_embedding\"))\n",
    "kernel.add_plugin(TextMemoryPlugin(memory), \"TextMemoryPluginACDB\")\n",
    "print(\"Registered Azure Cosmos DB Memory Store...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Generate embeddings and Create Database records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the helper function with the JSON data file to generate embeddings and create or update the database records.\n",
    "\n",
    "If the records already exit it will skip it.\n",
    "\n",
    "Records are identified by their ids.\n",
    "\n",
    "The data used here is a dummy data which you can replace with your own.\n",
    "\n",
    "**Note that you need to specify id, text, and description fields.\n",
    "The text field is what gets converted to embeddings.**\n",
    "\n",
    "See the helper function definition for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting data to Azure Cosmos DB Memory Store...\n",
      "Skipping item already exits: 165 / 344\r"
     ]
    },
    {
     "ename": "ServiceResponseException",
     "evalue": "(\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_text_embedding.AzureTextEmbedding'> service failed to generate embeddings\", APIConnectionError('Connection error.'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:69\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:373\u001b[0m, in \u001b[0;36mAsyncHTTPTransport.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 373\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_async_request(req)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mAsyncIterable)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpcore\\_async\\connection_pool.py:216\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpcore\\_async\\connection_pool.py:196\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mhandle_async_request(\n\u001b[0;32m    197\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpcore\\_async\\connection.py:99\u001b[0m, in \u001b[0;36mAsyncHTTPConnection.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpcore\\_async\\connection.py:76\u001b[0m, in \u001b[0;36mAsyncHTTPConnection.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect(request)\n\u001b[0;32m     78\u001b[0m     ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpcore\\_async\\connection.py:122\u001b[0m, in \u001b[0;36mAsyncHTTPConnection._connect\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnect_tcp\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m--> 122\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_backend\u001b[38;5;241m.\u001b[39mconnect_tcp(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    123\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpcore\\_backends\\auto.py:30\u001b[0m, in \u001b[0;36mAutoBackend.connect_tcp\u001b[1;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_backend()\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mconnect_tcp(\n\u001b[0;32m     31\u001b[0m     host,\n\u001b[0;32m     32\u001b[0m     port,\n\u001b[0;32m     33\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m     34\u001b[0m     local_address\u001b[38;5;241m=\u001b[39mlocal_address,\n\u001b[0;32m     35\u001b[0m     socket_options\u001b[38;5;241m=\u001b[39msocket_options,\n\u001b[0;32m     36\u001b[0m )\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpcore\\_backends\\anyio.py:114\u001b[0m, in \u001b[0;36mAnyIOBackend.connect_tcp\u001b[1;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[0;32m    109\u001b[0m exc_map \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;167;01mTimeoutError\u001b[39;00m: ConnectTimeout,\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[0;32m    112\u001b[0m     anyio\u001b[38;5;241m.\u001b[39mBrokenResourceError: ConnectError,\n\u001b[0;32m    113\u001b[0m }\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39mfail_after(timeout):\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[1;34m(map)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[1;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mConnectError\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\openai\\_base_client.py:1515\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1514\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1515\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m   1516\u001b[0m         request,\n\u001b[0;32m   1517\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1519\u001b[0m     )\n\u001b[0;32m   1520\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpx\\_client.py:1661\u001b[0m, in \u001b[0;36mAsyncClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m   1659\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m-> 1661\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m   1662\u001b[0m     request,\n\u001b[0;32m   1663\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m   1664\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m   1665\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m   1666\u001b[0m )\n\u001b[0;32m   1667\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpx\\_client.py:1689\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m   1688\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1689\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m   1690\u001b[0m         request,\n\u001b[0;32m   1691\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m   1692\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m   1693\u001b[0m     )\n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpx\\_client.py:1726\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m   1724\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[1;32m-> 1726\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m   1727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpx\\_client.py:1763\u001b[0m, in \u001b[0;36mAsyncClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1762\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1763\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m transport\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, AsyncByteStream)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:372\u001b[0m, in \u001b[0;36mAsyncHTTPTransport.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    360\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    361\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    362\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    370\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    371\u001b[0m )\n\u001b[1;32m--> 372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m    373\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_async_request(req)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:86\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mConnectError\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:80\u001b[0m, in \u001b[0;36mOpenAIHandler._send_embedding_request\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings\u001b[38;5;241m.\u001b[39mprepare_settings_dict())\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_usage(response)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\openai\\resources\\embeddings.py:214\u001b[0m, in \u001b[0;36mAsyncEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    216\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(params, embedding_create_params\u001b[38;5;241m.\u001b[39mEmbeddingCreateParams),\n\u001b[0;32m    217\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    218\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers,\n\u001b[0;32m    219\u001b[0m         extra_query\u001b[38;5;241m=\u001b[39mextra_query,\n\u001b[0;32m    220\u001b[0m         extra_body\u001b[38;5;241m=\u001b[39mextra_body,\n\u001b[0;32m    221\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    222\u001b[0m         post_parser\u001b[38;5;241m=\u001b[39mparser,\n\u001b[0;32m    223\u001b[0m     ),\n\u001b[0;32m    224\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mCreateEmbeddingResponse,\n\u001b[0;32m    225\u001b[0m )\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\openai\\_base_client.py:1783\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1780\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1781\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1782\u001b[0m )\n\u001b[1;32m-> 1783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\openai\\_base_client.py:1486\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1477\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m   1478\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1479\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1484\u001b[0m     remaining_retries: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1485\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[1;32m-> 1486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1487\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1488\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1489\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1490\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1491\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m   1492\u001b[0m     )\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\openai\\_base_client.py:1539\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1540\u001b[0m         options,\n\u001b[0;32m   1541\u001b[0m         cast_to,\n\u001b[0;32m   1542\u001b[0m         retries,\n\u001b[0;32m   1543\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1544\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1545\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1546\u001b[0m     )\n\u001b[0;32m   1548\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\openai\\_base_client.py:1539\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1540\u001b[0m         options,\n\u001b[0;32m   1541\u001b[0m         cast_to,\n\u001b[0;32m   1542\u001b[0m         retries,\n\u001b[0;32m   1543\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1544\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1545\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1546\u001b[0m     )\n\u001b[0;32m   1548\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\openai\\_base_client.py:1549\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1549\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1551\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl, response\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m.\u001b[39mreason_phrase\n\u001b[0;32m   1553\u001b[0m )\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m: Connection error.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mServiceResponseException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# cleaned-top-movies-chunked.json contains the top 344 movie from the IMDB movies dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# You can also try the text-sample.json which contains 107 Azure Service.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Replace the file name cleaned-top-movies-chunked.json with text-sample.json\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpserting data to Azure Cosmos DB Memory Store...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m upsert_data_to_memory_store(memory, store, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./src/data/cleaned-top-movies-chunked.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[71], line 32\u001b[0m, in \u001b[0;36mupsert_data_to_memory_store\u001b[1;34m(memory, store, data_file_path)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# if the record doesn't exist, we generate embeddings and save it to the database\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m already_created:\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m memory\u001b[38;5;241m.\u001b[39msave_information(\n\u001b[0;32m     33\u001b[0m         collection\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mitem[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;66;03m# the embedding is generated from the text field\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         text\u001b[38;5;241m=\u001b[39mitem[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     37\u001b[0m         description\u001b[38;5;241m=\u001b[39mitem[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     38\u001b[0m     )\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating embeddings and saving new item:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     41\u001b[0m         n,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m         end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     45\u001b[0m     )\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\semantic_kernel\\memory\\semantic_text_memory.py:57\u001b[0m, in \u001b[0;36mSemanticTextMemory.save_information\u001b[1;34m(self, collection, text, id, description, additional_metadata)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage\u001b[38;5;241m.\u001b[39mdoes_collection_exist(collection_name\u001b[38;5;241m=\u001b[39mcollection):\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage\u001b[38;5;241m.\u001b[39mcreate_collection(collection_name\u001b[38;5;241m=\u001b[39mcollection)\n\u001b[1;32m---> 57\u001b[0m embedding \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embeddings_generator\u001b[38;5;241m.\u001b[39mgenerate_embeddings([text]))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     58\u001b[0m data \u001b[38;5;241m=\u001b[39m MemoryRecord\u001b[38;5;241m.\u001b[39mlocal_record(\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m,\n\u001b[0;32m     60\u001b[0m     text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m     embedding\u001b[38;5;241m=\u001b[39membedding,\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage\u001b[38;5;241m.\u001b[39mupsert(collection_name\u001b[38;5;241m=\u001b[39mcollection, record\u001b[38;5;241m=\u001b[39mdata)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_text_embedding_base.py:38\u001b[0m, in \u001b[0;36mOpenAITextEmbeddingBase.generate_embeddings\u001b[1;34m(self, texts, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m     batch \u001b[38;5;241m=\u001b[39m texts[i : i \u001b[38;5;241m+\u001b[39m batch_size]  \u001b[38;5;66;03m# noqa: E203\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     settings\u001b[38;5;241m.\u001b[39minput \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m---> 38\u001b[0m     raw_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_embedding_request(\n\u001b[0;32m     39\u001b[0m         settings\u001b[38;5;241m=\u001b[39msettings,\n\u001b[0;32m     40\u001b[0m     )\n\u001b[0;32m     41\u001b[0m     raw_embeddings\u001b[38;5;241m.\u001b[39mextend(raw_embedding)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array(raw_embeddings)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:86\u001b[0m, in \u001b[0;36mOpenAIHandler._send_embedding_request\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [array(x\u001b[38;5;241m.\u001b[39membedding) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mdata]\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m service failed to generate embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m         ex,\n\u001b[0;32m     89\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[1;31mServiceResponseException\u001b[0m: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_text_embedding.AzureTextEmbedding'> service failed to generate embeddings\", APIConnectionError('Connection error.'))"
     ]
    }
   ],
   "source": [
    "# cleaned-top-movies-chunked.json contains the top 344 movie from the IMDB movies dataset\n",
    "# You can also try the text-sample.json which contains 107 Azure Service.\n",
    "# Replace the file name cleaned-top-movies-chunked.json with text-sample.json\n",
    "\n",
    "print(\"Upserting data to Azure Cosmos DB Memory Store...\")\n",
    "await upsert_data_to_memory_store(memory, store, \"./src/data/cleaned-top-movies-chunked.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Test the Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search function converts the query_term to a vector embedding and finds the similarity between it and the database records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceResponseException",
     "evalue": "(\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_text_embedding.AzureTextEmbedding'> service failed to generate embeddings\", APIConnectionError('Connection error.'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:69\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:373\u001b[0m, in \u001b[0;36mAsyncHTTPTransport.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 373\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_async_request(req)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mAsyncIterable)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpcore\\_async\\connection_pool.py:216\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpcore\\_async\\connection_pool.py:196\u001b[0m, in \u001b[0;36mAsyncConnectionPool.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mhandle_async_request(\n\u001b[0;32m    197\u001b[0m         pool_request\u001b[38;5;241m.\u001b[39mrequest\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpcore\\_async\\connection.py:99\u001b[0m, in \u001b[0;36mAsyncHTTPConnection.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpcore\\_async\\connection.py:76\u001b[0m, in \u001b[0;36mAsyncHTTPConnection.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect(request)\n\u001b[0;32m     78\u001b[0m     ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpcore\\_async\\connection.py:122\u001b[0m, in \u001b[0;36mAsyncHTTPConnection._connect\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnect_tcp\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m--> 122\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_backend\u001b[38;5;241m.\u001b[39mconnect_tcp(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    123\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpcore\\_backends\\auto.py:30\u001b[0m, in \u001b[0;36mAutoBackend.connect_tcp\u001b[1;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_backend()\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mconnect_tcp(\n\u001b[0;32m     31\u001b[0m     host,\n\u001b[0;32m     32\u001b[0m     port,\n\u001b[0;32m     33\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m     34\u001b[0m     local_address\u001b[38;5;241m=\u001b[39mlocal_address,\n\u001b[0;32m     35\u001b[0m     socket_options\u001b[38;5;241m=\u001b[39msocket_options,\n\u001b[0;32m     36\u001b[0m )\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpcore\\_backends\\anyio.py:114\u001b[0m, in \u001b[0;36mAnyIOBackend.connect_tcp\u001b[1;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[0;32m    109\u001b[0m exc_map \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;167;01mTimeoutError\u001b[39;00m: ConnectTimeout,\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[0;32m    112\u001b[0m     anyio\u001b[38;5;241m.\u001b[39mBrokenResourceError: ConnectError,\n\u001b[0;32m    113\u001b[0m }\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m anyio\u001b[38;5;241m.\u001b[39mfail_after(timeout):\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[1;34m(map)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[1;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mConnectError\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\openai\\_base_client.py:1515\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1514\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1515\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m   1516\u001b[0m         request,\n\u001b[0;32m   1517\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1519\u001b[0m     )\n\u001b[0;32m   1520\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpx\\_client.py:1661\u001b[0m, in \u001b[0;36mAsyncClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m   1659\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m-> 1661\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_auth(\n\u001b[0;32m   1662\u001b[0m     request,\n\u001b[0;32m   1663\u001b[0m     auth\u001b[38;5;241m=\u001b[39mauth,\n\u001b[0;32m   1664\u001b[0m     follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m   1665\u001b[0m     history\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m   1666\u001b[0m )\n\u001b[0;32m   1667\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpx\\_client.py:1689\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m   1688\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1689\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_handling_redirects(\n\u001b[0;32m   1690\u001b[0m         request,\n\u001b[0;32m   1691\u001b[0m         follow_redirects\u001b[38;5;241m=\u001b[39mfollow_redirects,\n\u001b[0;32m   1692\u001b[0m         history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m   1693\u001b[0m     )\n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpx\\_client.py:1726\u001b[0m, in \u001b[0;36mAsyncClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m   1724\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[1;32m-> 1726\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_single_request(request)\n\u001b[0;32m   1727\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpx\\_client.py:1763\u001b[0m, in \u001b[0;36mAsyncClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1762\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1763\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m transport\u001b[38;5;241m.\u001b[39mhandle_async_request(request)\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, AsyncByteStream)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:372\u001b[0m, in \u001b[0;36mAsyncHTTPTransport.handle_async_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    360\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    361\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    362\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    370\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    371\u001b[0m )\n\u001b[1;32m--> 372\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m    373\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_async_request(req)\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\httpx\\_transports\\default.py:86\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mConnectError\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:80\u001b[0m, in \u001b[0;36mOpenAIHandler._send_embedding_request\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msettings\u001b[38;5;241m.\u001b[39mprepare_settings_dict())\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_usage(response)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\openai\\resources\\embeddings.py:214\u001b[0m, in \u001b[0;36mAsyncEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    216\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(params, embedding_create_params\u001b[38;5;241m.\u001b[39mEmbeddingCreateParams),\n\u001b[0;32m    217\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    218\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers,\n\u001b[0;32m    219\u001b[0m         extra_query\u001b[38;5;241m=\u001b[39mextra_query,\n\u001b[0;32m    220\u001b[0m         extra_body\u001b[38;5;241m=\u001b[39mextra_body,\n\u001b[0;32m    221\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    222\u001b[0m         post_parser\u001b[38;5;241m=\u001b[39mparser,\n\u001b[0;32m    223\u001b[0m     ),\n\u001b[0;32m    224\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mCreateEmbeddingResponse,\n\u001b[0;32m    225\u001b[0m )\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\openai\\_base_client.py:1783\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1780\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1781\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1782\u001b[0m )\n\u001b[1;32m-> 1783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\openai\\_base_client.py:1486\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1477\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m   1478\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1479\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1484\u001b[0m     remaining_retries: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1485\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[1;32m-> 1486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1487\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1488\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1489\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1490\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1491\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m   1492\u001b[0m     )\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\openai\\_base_client.py:1539\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1540\u001b[0m         options,\n\u001b[0;32m   1541\u001b[0m         cast_to,\n\u001b[0;32m   1542\u001b[0m         retries,\n\u001b[0;32m   1543\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1544\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1545\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1546\u001b[0m     )\n\u001b[0;32m   1548\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\openai\\_base_client.py:1539\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1540\u001b[0m         options,\n\u001b[0;32m   1541\u001b[0m         cast_to,\n\u001b[0;32m   1542\u001b[0m         retries,\n\u001b[0;32m   1543\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1544\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1545\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1546\u001b[0m     )\n\u001b[0;32m   1548\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\openai\\_base_client.py:1549\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[1;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1549\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1551\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl, response\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m.\u001b[39mreason_phrase\n\u001b[0;32m   1553\u001b[0m )\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m: Connection error.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mServiceResponseException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# each time it calls the embedding model to generate embeddings from your query\u001b[39;00m\n\u001b[0;32m      2\u001b[0m query_term \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat do you know about the godfather?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m memory\u001b[38;5;241m.\u001b[39msearch(collection_name, query_term)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\semantic_kernel\\memory\\semantic_text_memory.py:141\u001b[0m, in \u001b[0;36mSemanticTextMemory.search\u001b[1;34m(self, collection, query, limit, min_relevance_score, with_embeddings)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    123\u001b[0m     collection: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m     with_embeddings: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    128\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[MemoryQueryResult]:\n\u001b[0;32m    129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search the memory (calls the memory store's get_nearest_matches method).\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Arguments:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;124;03m        List[MemoryQueryResult] -- The list of MemoryQueryResult found.\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embeddings_generator\u001b[38;5;241m.\u001b[39mgenerate_embeddings([query]))[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    142\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage\u001b[38;5;241m.\u001b[39mget_nearest_matches(\n\u001b[0;32m    143\u001b[0m         collection_name\u001b[38;5;241m=\u001b[39mcollection,\n\u001b[0;32m    144\u001b[0m         embedding\u001b[38;5;241m=\u001b[39mquery_embedding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m         with_embeddings\u001b[38;5;241m=\u001b[39mwith_embeddings,\n\u001b[0;32m    148\u001b[0m     )\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [MemoryQueryResult\u001b[38;5;241m.\u001b[39mfrom_memory_record(r[\u001b[38;5;241m0\u001b[39m], r[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_text_embedding_base.py:38\u001b[0m, in \u001b[0;36mOpenAITextEmbeddingBase.generate_embeddings\u001b[1;34m(self, texts, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m     batch \u001b[38;5;241m=\u001b[39m texts[i : i \u001b[38;5;241m+\u001b[39m batch_size]  \u001b[38;5;66;03m# noqa: E203\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     settings\u001b[38;5;241m.\u001b[39minput \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m---> 38\u001b[0m     raw_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_embedding_request(\n\u001b[0;32m     39\u001b[0m         settings\u001b[38;5;241m=\u001b[39msettings,\n\u001b[0;32m     40\u001b[0m     )\n\u001b[0;32m     41\u001b[0m     raw_embeddings\u001b[38;5;241m.\u001b[39mextend(raw_embedding)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array(raw_embeddings)\n",
      "File \u001b[1;32mc:\\gitlab\\rag-semantic-kernel-mongodb-vcore\\.venv\\lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:86\u001b[0m, in \u001b[0;36mOpenAIHandler._send_embedding_request\u001b[1;34m(self, settings)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [array(x\u001b[38;5;241m.\u001b[39membedding) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mdata]\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m service failed to generate embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     88\u001b[0m         ex,\n\u001b[0;32m     89\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[1;31mServiceResponseException\u001b[0m: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.azure_text_embedding.AzureTextEmbedding'> service failed to generate embeddings\", APIConnectionError('Connection error.'))"
     ]
    }
   ],
   "source": [
    "# each time it calls the embedding model to generate embeddings from your query\n",
    "query_term = \"What do you know about the godfather?\"\n",
    "result = await memory.search(collection_name, query_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result is: The Godfather: The aging patriarch of an organized crime dynasty transfers control of his clandestine empire to his reluctant son.\n",
      "Relevance Score: 0.875003419815884\n",
      "Full Record: {\"text\": \"The Godfather: The aging patriarch of an organized crime dynasty transfers control of his clandestine empire to his reluctant son.\", \"description\": \"The Godfather\", \"additional_metadata\": null}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Result is: {result[0].text}\\nRelevance Score: {result[0].relevance}\\nFull Record: {result[0].additional_metadata}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Create chat function with Azure OpenAI chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    You are a chatbot that can have a conversations about any topic related to the provided context.\n",
    "    Give explicit answers from the provided context or say 'I don't know' if it does not have an answer.\n",
    "    provided context: {{$db_record}}\n",
    "\n",
    "    User: {{$query_term}}\n",
    "    Chatbot:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import OpenAITextPromptExecutionSettings\n",
    "\n",
    "execution_settings = OpenAITextPromptExecutionSettings(\n",
    "    service_id=\"chat_completion\", ai_model_id=chat_model_deployment_name, max_tokens=500, temperature=0.0, top_p=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.prompt_template import PromptTemplateConfig\n",
    "from semantic_kernel.prompt_template.input_variable import InputVariable\n",
    "\n",
    "chat_prompt_template_config = PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    name=\"grounded_response\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"db_record\", description=\"The database record\", is_required=True),\n",
    "        InputVariable(name=\"query_term\", description=\"The user input\", is_required=True),\n",
    "    ],\n",
    "    execution_settings=execution_settings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_function = kernel.add_function(\n",
    "    function_name=\"ChatGPTFunc\", plugin_name=\"chatGPTPlugin\", prompt_template_config=chat_prompt_template_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "\n",
    "completions_result = await kernel.invoke(\n",
    "    chat_function, KernelArguments(query_term=query_term, db_record=result[0].additional_metadata)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Godfather is a movie about the aging patriarch of an organized crime dynasty who transfers control of his clandestine empire to his reluctant son.\n"
     ]
    }
   ],
   "source": [
    "print(completions_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Testing the RAG flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Hey\n",
      "Response:\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "Question:\n",
      "Do you know any crime dynasty movies?\n",
      "Response:\n",
      "Yes, \"The Godfather\" is a classic crime dynasty movie.\n",
      "\n",
      "Question:\n",
      "can you recommend me movies like the god father?\n",
      "Response:\n",
      "Sure, if you enjoyed The Godfather, you might also like movies such as Goodfellas, The Departed, Scarface, and The Sopranos (TV series).\n",
      "\n",
      "Question:\n",
      "thanks, bye!\n",
      "Response:\n",
      "You're welcome! Goodbye!\n",
      "\n",
      "Question:\n",
      "exit\n",
      "Response:\n",
      "Goodbye!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "query_term = \"\"\n",
    "search_result = \"\"\n",
    "completions_result = \"\"\n",
    "\n",
    "while query_term != \"exit\":\n",
    "    query_term = input(\"Enter a query: \")\n",
    "    search_result = await memory.search(collection_name, query_term)\n",
    "    completions_result = kernel.invoke_stream(\n",
    "        chat_function, KernelArguments(query_term=query_term, db_record=search_result[0].additional_metadata)\n",
    "    )\n",
    "    print(f\"Question:\\n{query_term}\\nResponse:\")\n",
    "    async for completion in completions_result:\n",
    "        print(str(completion[0]), end=\"\")\n",
    "    print(\"\\n\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **[Optional]** Adding Chat History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chat history is local (i.e. in your computer's RAM) and not persisted anywhere beyond the life of this Jupyter session.\n",
    "In this chat scenario, as the user talks back and forth with the bot, the chat context gets populated with the history of the conversation. During each new run of the kernel, the kernel arguments and chat history can provide the AI with its variables' content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_prompt = \"\"\"\n",
    "    You are a chatbot that can have a conversations about any topic related to the provided context.\n",
    "    Give explicit answers from the provided context or say 'I don't know' if it does not have an answer.\n",
    "    provided context: {{$db_record}}\n",
    "\n",
    "    {{$history}}\n",
    "    \n",
    "    User: {{$query_term}}\n",
    "    Chatbot:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_hist_template_config = PromptTemplateConfig(\n",
    "    template=history_prompt,\n",
    "    name=\"grounded_response_history\",\n",
    "    template_format=\"semantic-kernel\",\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"db_record\", description=\"The database record\", is_required=True),\n",
    "        InputVariable(name=\"query_term\", description=\"The user input\", is_required=True),\n",
    "        InputVariable(name=\"history\", description=\"The chat histroy\", is_required=True),\n",
    "    ],\n",
    "    execution_settings=execution_settings,\n",
    ")\n",
    "\n",
    "chat_history_function = kernel.add_function(\n",
    "    function_name=\"ChatGPTFuncHist\", plugin_name=\"chatGPTPluginHist\", prompt_template_config=chat_prompt_hist_template_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_system_message(\"You are a helpful chatbot who is good about giving movie recommendations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:\n",
      "Hey\n",
      "Response:\n",
      "Hello! How can I assist you today?\n",
      "\n",
      "Question:\n",
      "Do you know any comedy movies?\n",
      "Response:\n",
      "Yes, I can recommend some comedy movies for you. What type of comedy are you in the mood for? Romantic comedy, slapstick, satire, parody, or something else?\n",
      "\n",
      "Question:\n",
      "paradoy\n",
      "Response:\n",
      "Great choice! Here are some parody movies that you might enjoy:\n",
      "\n",
      "1. Airplane! (1980)\n",
      "2. The Naked Gun: From the Files of Police Squad! (1988)\n",
      "3. This Is Spinal Tap (1984)\n",
      "4. Austin Powers: International Man of Mystery (1997)\n",
      "5. Spaceballs (1987)\n",
      "6. Robin Hood: Men in Tights (1993)\n",
      "7. Hot Shots! (1991)\n",
      "8. Scary Movie (2000)\n",
      "9. Shaun of the Dead (2004)\n",
      "10. The Princess Bride (1987)\n",
      "\n",
      "I hope you find one that you enjoy!\n",
      "\n",
      "Question:\n",
      "can you tell me more about the first movie?\n",
      "Response:\n",
      "Sure! \"Airplane!\" is a classic comedy movie from 1980 that is a parody of disaster movies. The movie follows the story of a former fighter pilot named Ted Striker, who is traumatized by his experiences in the war and is now afraid to fly. However, when the passengers and crew of a commercial airliner fall ill from food poisoning, Ted must overcome his fears and land the plane safely. The movie is known for its absurd humor, visual gags, and puns, and features a star-studded cast including Leslie Nielsen, Robert Hays, and Julie Hagerty. It's definitely worth a watch if you're in the mood for a good laugh!\n",
      "\n",
      "Question:\n",
      "exit\n",
      "Response:\n",
      "Goodbye! Don't hesitate to come back if you have any more questions or if you need any assistance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "query_term = \"\"\n",
    "search_result = \"\"\n",
    "completions_result = \"\"\n",
    "\n",
    "while query_term != \"exit\":\n",
    "    query_term = input(\"Enter a query: \")\n",
    "    chat_history.add_user_message(query_term)\n",
    "\n",
    "    search_result = await memory.search(collection_name, query_term) # vector search\n",
    "    \n",
    "    completions_result = await kernel.invoke(\n",
    "        chat_history_function, KernelArguments(query_term=query_term, db_record=search_result[0].additional_metadata, history=chat_history)\n",
    "    ) # RAG\n",
    "    chat_history.add_assistant_message(str(completions_result))\n",
    "\n",
    "    print(f\"Question:\\n{query_term}\\nResponse:\")\n",
    "    print(str(completions_result), end=\"\")\n",
    "    print(\"\\n\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After chatting for a while, we have built a growing history, which we are attaching to each prompt and which contains the full conversation. Let's take a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<chat_history><message role=\"system\">You are a helpful chatbot who is good about giving movie recommendations.</message><message role=\"user\">Hey</message><message role=\"assistant\">Hello! How can I assist you today?</message><message role=\"user\">Do you know any comedy movies?</message><message role=\"assistant\">Yes, I can recommend some comedy movies for you. What type of comedy are you in the mood for? Romantic comedy, slapstick, satire, parody, or something else?</message><message role=\"user\">paradoy</message><message role=\"assistant\">Great choice! Here are some parody movies that you might enjoy:\n",
      "\n",
      "1. Airplane! (1980)\n",
      "2. The Naked Gun: From the Files of Police Squad! (1988)\n",
      "3. This Is Spinal Tap (1984)\n",
      "4. Austin Powers: International Man of Mystery (1997)\n",
      "5. Spaceballs (1987)\n",
      "6. Robin Hood: Men in Tights (1993)\n",
      "7. Hot Shots! (1991)\n",
      "8. Scary Movie (2000)\n",
      "9. Shaun of the Dead (2004)\n",
      "10. The Princess Bride (1987)\n",
      "\n",
      "I hope you find one that you enjoy!</message><message role=\"user\">can you tell me more about the first movie?</message><message role=\"assistant\">Sure! \"Airplane!\" is a classic comedy movie from 1980 that is a parody of disaster movies. The movie follows the story of a former fighter pilot named Ted Striker, who is traumatized by his experiences in the war and is now afraid to fly. However, when the passengers and crew of a commercial airliner fall ill from food poisoning, Ted must overcome his fears and land the plane safely. The movie is known for its absurd humor, visual gags, and puns, and features a star-studded cast including Leslie Nielsen, Robert Hays, and Julie Hagerty. It's definitely worth a watch if you're in the mood for a good laugh!</message><message role=\"user\">exit</message><message role=\"assistant\">Goodbye! Don't hesitate to come back if you have any more questions or if you need any assistance.</message></chat_history>\n"
     ]
    }
   ],
   "source": [
    "print(chat_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
